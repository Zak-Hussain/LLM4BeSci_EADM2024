{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Workshop 2\n",
    "\n",
    "In this analysis...\n",
    "\n",
    "By the end of this analysis, you will have learned how:"
   ],
   "id": "b869db79a8e2b860"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Environment Setup ",
   "id": "ec251e1c2719b28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:  # If in Google Colab environment\n",
    "    # Mount google drive to enable access to data files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Installing requisite packages\n",
    "    !pip install --upgrade transformers openai  &> /dev/null\n",
    "\n",
    "    # Change working directory \n",
    "    %cd /content/drive/MyDrive/LLM4BeSci_EADM2024/workshop_3"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from huggingface_hub import InferenceClient\n",
    "import textwrap"
   ],
   "id": "2948ad848d628827"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Zero-shot Classification: Media Bias\n",
    "We begin by loading the dataset as a `pandas.DataFrame`:"
   ],
   "id": "714e83d6d0c68d78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "media_bias_test = pd.read_csv('media_bias_test.csv')\n",
    "media_bias_test"
   ],
   "id": "b943e40b73abab85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize client\n",
    "api_key = '<your access token here>' \n",
    "client = InferenceClient(token=api_key)\n",
    "\n",
    "# Zero-shot classification prompt\n",
    "zero_shot_prompt = \"Is this text neutral or partisan? Strictly answer with only 'neutral' or 'partisan':\\n\"\n",
    "\n",
    "zero_shot_labels = []\n",
    "for tweet in tqdm(media_bias_test['text']):    \n",
    "    \n",
    "    # Zero-shot classification \n",
    "    output = client.chat_completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a thoughtful political scientist who accurately distinguishes neutral and partisan messages\"},\n",
    "            {\"role\": \"user\", \"content\": zero_shot_prompt + tweet}\n",
    "        ],\n",
    "        model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        max_tokens=100,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    # Accessing the text output and lowercasing it\n",
    "    output = output.choices[0].message.content.lower()\n",
    "    \n",
    "    # Extract label and append to list\n",
    "    label = 'neutral' if 'neutral' in output else 'partisan' if 'partisan' in output else 'nan' # \n",
    "    zero_shot_labels.append(label)\n",
    "\n",
    "# Add zero-shot labels to dataframe\n",
    "media_bias_test['zero_shot_label'] = zero_shot_labels\n",
    "media_bias_test"
   ],
   "id": "ecf9f91c8f9b6e6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Comparing zero-shot and actual labels\n",
    "print(f'Zero-shot accuracy: {(media_bias_test[\"zero_shot_label\"] == media_bias_test[\"bias\"]).mean()}')"
   ],
   "id": "1566347fad5c0d8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Confusion matrix\n",
    "confusion = pd.crosstab(media_bias_test['bias'], media_bias_test['zero_shot_label'])\n",
    "sns.heatmap(confusion, annot=True)"
   ],
   "id": "28a14100899bbea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**TASK 1**: Try playing around with the prompt. Can you find one that increases the accuracy of Llama 3?**TASK 2**: Try playing around with different `temperature` values (e.g. 0.5, 1.0, and 3.0) and see how it affects the accuracy.",
   "id": "a095b45c98303886"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Synthetic Participants: The Berlin Numeracy Test\n",
    "In this section, we will explore the usage of causal LLMs as synthetic participants in a psychological experiment. We will again use Phi-3, this time to solve the [Berlin Numeracy Test](https://doi.org/10.1017/S1930297500001819). This is a widely used test to measure an individual's ability to understand and apply statistical concepts. \n",
    "\n",
    "The test consists of four questions that require a basic understanding of probability and statistics. In this exercise, we will ask Phi-3 to solve these questions. Phi-3 will provide an answer to each question, and we will evaluate the quality of the response.\n",
    "\n",
    "The code begins by defining the four questions: "
   ],
   "id": "1b3fa1e8bebb0454"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "q1 = \"\"\"\n",
    "Imagine we are throwing a five-sided die 50 times. On average, out of these 50 throws how many times would this five-sided die show an odd number (1, 3 or 5)?\n",
    "\"\"\"\n",
    "\n",
    "q2 = \"\"\"\n",
    "Out of 1,000 people in a small town 500 are members of a choir. Out of these 500 members in the choir 100 are men. Out of the 500 inhabitants that are not in the choir 300 are men. What is the probability that a randomly drawn man is a member of the choir? (please indicate the probability in percent).\n",
    "\"\"\"\n",
    "\n",
    "q3 = \"\"\"\n",
    "Imagine we are throwing a loaded die (6 sides). The probability that the die shows a 6 is twice as high as the probability of each of the other numbers. On average, out of these 70 throws, how many times would the die show the number 6?\n",
    "\"\"\"\n",
    "\n",
    "q4 = \"\"\"\n",
    "In a forest 20% of mushrooms are red, 50% brown and 30% white. A red mushroom is poisonous with a probability of 20%. A mushroom that is not red is poisonous with a probability of 5%. What is the probability that a poisonous mushroom in the forest is red?\n",
    "\"\"\""
   ],
   "id": "29b04f4177d7b5e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "api_key = '<our access token here>'\n",
    "\n",
    "# Loop through questions and generate responses\n",
    "for i, question in enumerate([q1, q2, q3, q4]):\n",
    "    print('-------------------------')   \n",
    "    \n",
    "    # Define prompt\n",
    "    question = question + \" Make your answer as brief as possible using less than 50 words.\"\n",
    "    \n",
    "    output = client.chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant who is good at solving numerical problems.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ],\n",
    "    model=\"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "    max_tokens=100,\n",
    "    temperature=0.0\n",
    "    )\n",
    "    \n",
    "    # Accessing the text output \n",
    "    response = output.choices[0].message.content\n",
    "    \n",
    "    # Format question and response for printing\n",
    "    question = '\\n'.join(textwrap.wrap(question, 100))\n",
    "    response = '\\n'.join(textwrap.wrap(response, 100))\n",
    "    print(f\"Question {i+1}: {question} \\n\\nAnswer: {response}\\n\")"
   ],
   "id": "71c9c283b1ebabf9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "[ADD EVALUATION]\n",
    "\n",
    "[ADD EXERCISES]"
   ],
   "id": "e97094deb99953c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
